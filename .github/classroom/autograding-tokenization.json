{
  "tests": [
    {
      "name": "Run tokenization tests",
      "run": "PYTHONPATH=. /data/bin/miniconda3/envs/jupyter-actions/bin/pytest -vs tests/tokenization/tokenizer_test.py",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 20,
      "points": 200
    },
    {
      "name": "feedback",
      "run": "echo -e '\\n\\nğŸ’¬ğŸ’¬ğŸ’¬ ĞÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ¿Ğ¾ Ğ”Ğ— https://forms.gle/RgBdUuegx7BFbc5X6 ğŸ’¬ğŸ’¬ğŸ’¬\\n\\n'",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 1,
      "points": 0
    }
  ]
}
