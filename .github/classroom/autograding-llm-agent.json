{
  "tests": [
    {
      "name": "Wait for VLLM to start. This could take up to 5 minutes.",
      "run": "while ! curl http://127.0.0.1:8000/v1/models | grep -q 'Qwen/Qwen2.5-7B-Instruct-AWQ'; do sleep 1; done",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 10,
      "points": 0
    },
    {
      "name": "run evaluation",
      "run": "PYTHONPATH=. /data/bin/miniconda3/envs/jupyter-actions/bin/python tests/llm-agent/run_evaluation.py --out llm-agent-score.txt",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 15,
      "points": 0
    },
    {
      "name": "score >= 50",
      "run": "ls llm-agent-score.txt && perl -lnE ' exit(int($_) >= 50 ? 0 : 1) ' llm-agent-score.txt",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 5,
      "points": 100
    },
    {
      "name": "score >= 70",
      "run": "ls llm-agent-score.txt && perl -lnE ' exit(int($_) >= 70 ? 0 : 1) ' llm-agent-score.txt",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 5,
      "points": 100
    },
    {
      "name": "feedback",
      "run": "echo -e '\\n\\nğŸ’¬ğŸ’¬ğŸ’¬ ĞÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ¿Ğ¾ Ğ”Ğ— https://forms.gle/ySbswCdyRzGYTBwL6 ğŸ’¬ğŸ’¬ğŸ’¬\\n\\n'",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 1,
      "points": 0
    }
  ]
}
