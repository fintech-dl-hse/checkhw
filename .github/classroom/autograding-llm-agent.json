{
  "tests": [
    {
      "name": "run evaluation",
      "run": "/data/bin/miniconda3/envs/jupyter-actions/bin/python tests/llm-agent/run_evaluation.py --out llm-agent-score.txt",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 15,
      "points": 0
    },
    {
      "name": "score >= 50",
      "run": "ls llm-agent-score.txt && perl -lnE ' exit(int($_) >= 50 ? 0 : 1) ' llm-agent-score.txt",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 5,
      "points": 100
    },
    {
      "name": "score >= 70",
      "run": "ls llm-agent-score.txt && perl -lnE ' exit(int($_) >= 70 ? 0 : 1) ' llm-agent-score.txt",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 5,
      "points": 100
    },
    {
      "name": "feedback",
      "run": "echo -e '\\n\\nğŸ’¬ğŸ’¬ğŸ’¬ ĞÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½ÑƒÑ ÑĞ²ÑĞ·ÑŒ Ğ¿Ğ¾ Ğ”Ğ— https://forms.gle/ySbswCdyRzGYTBwL6 ğŸ’¬ğŸ’¬ğŸ’¬\\n\\n'",
      "input": "",
      "output": "",
      "comparison": "included",
      "timeout": 1,
      "points": 0
    }
  ]
}
